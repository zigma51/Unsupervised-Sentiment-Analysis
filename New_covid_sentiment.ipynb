{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "New_covid_sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EcLiUIqtO0S",
        "colab_type": "text"
      },
      "source": [
        "# Implementation of sentiment analysis using Word Vectors, Tfidf weights and K-means Clustering algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCvZPOfeDPkB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "a164b641-c8ce-46ad-dc3c-327c14071da2"
      },
      "source": [
        "# Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from re import sub\n",
        "import string\n",
        "import multiprocessing\n",
        "\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.test.utils import get_tmpfile\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "\n",
        "from time import time \n",
        "from collections import defaultdict\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "from IPython.display import display\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "from gensim.parsing.preprocessing import remove_stopwords"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Irqb7kjDwSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading of dataset\n",
        "df1 = pd.read_excel('/content/drive/My Drive/data/covid_sentiment.xlsx')\n",
        "df = df1.dropna().drop_duplicates().reset_index(drop=True)\n",
        "df = df.drop('Unnamed: 0',axis=1)\n",
        "df = df.drop('Unnamed: 0.1',axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R0PStjKD3Hk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "fa681351-c127-48c8-9d79-98679eee2e44"
      },
      "source": [
        "# Visualizing dataset\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date-Time</th>\n",
              "      <th>Title</th>\n",
              "      <th>Content</th>\n",
              "      <th>Article URL</th>\n",
              "      <th>All_Content</th>\n",
              "      <th>Summary</th>\n",
              "      <th>sentiment_prediction</th>\n",
              "      <th>Actual_Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21 Apr, 2020, 01:52PM IST</td>\n",
              "      <td>Covid-19: Karnataka to collect samples of jour...</td>\n",
              "      <td>The directions followed a request from Educati...</td>\n",
              "      <td>https://economictimes.indiatimes.com//news/pol...</td>\n",
              "      <td>After 53 journalists in Mumbai were found posi...</td>\n",
              "      <td>After 53 journalists in Mumbai were found posi...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20 Apr, 2020, 07:33AM IST</td>\n",
              "      <td>Newborn tests positive for COVID-19 in Rajasth...</td>\n",
              "      <td>Dr Shadab Ali, in-charge of Basni primary heal...</td>\n",
              "      <td>https://economictimes.indiatimes.com//news/pol...</td>\n",
              "      <td>Jaipur: A newborn baby has tested positive for...</td>\n",
              "      <td>Jaipur: A newborn baby has tested positive for...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18 Apr, 2020, 12:17PM IST</td>\n",
              "      <td>Police officer dies of COVID-19 in Ludhiana</td>\n",
              "      <td>The 52-year-old Ludhiana assistant commissione...</td>\n",
              "      <td>https://economictimes.indiatimes.com//news/pol...</td>\n",
              "      <td>The 52-year-old Ludhiana assistant commissione...</td>\n",
              "      <td>\"Sad to share that we had lost Gurmail Singh K...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10 Apr, 2020, 02:14AM IST</td>\n",
              "      <td>The Covid curve: How the states fare</td>\n",
              "      <td>Data suggests that some of the 15 states/UTs n...</td>\n",
              "      <td>https://economictimes.indiatimes.com//news/pol...</td>\n",
              "      <td>Fifteen Indian states and Union Territories ac...</td>\n",
              "      <td>Fifteen Indian states and Union Territories ac...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15 Apr, 2020, 06:33PM IST</td>\n",
              "      <td>Covid fight needs women to be agents of change</td>\n",
              "      <td>Women civil servants and police at Centre, sta...</td>\n",
              "      <td>https://economictimes.indiatimes.com//news/pol...</td>\n",
              "      <td>By LAKSHMI PURI In our Covid wars, itâ€™s time t...</td>\n",
              "      <td>Pending mass vaccination, Nagarik Dharma Yuddh...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Date-Time  ... Actual_Sentiment\n",
              "0  21 Apr, 2020, 01:52PM IST  ...                0\n",
              "1  20 Apr, 2020, 07:33AM IST  ...                0\n",
              "2  18 Apr, 2020, 12:17PM IST  ...                0\n",
              "3  10 Apr, 2020, 02:14AM IST  ...                0\n",
              "4  15 Apr, 2020, 06:33PM IST  ...                1\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4dBS9mUHs9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51GXOSYrD4st",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Pre-processing\n",
        "\n",
        "\n",
        "#df['Summary'] = df['Summary'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in (stop)]))\n",
        "\n",
        "\n",
        "def text_to_word_list(text):\n",
        "    text = str(text)\n",
        "    text = text.lower()\n",
        "\n",
        "    # Clean the text\n",
        "    text = sub(r\"[^A-Za-z0-9^,!?.\\/'+]\", \" \", text)\n",
        "    text = sub(r\",\", \" \", text)\n",
        "    text = sub(r\"\\.\", \" \", text)\n",
        "    text = sub(r\"!\", \" ! \", text)\n",
        "    text = sub(r\"\\?\", \" ? \", text)\n",
        "    text = sub(r\"'\", \"\", text)\n",
        "    text = sub(r'\"', \" \", text)\n",
        "    text = sub(r\":\", \" : \", text)\n",
        "\n",
        "    # text = sub(r\"<br>\", \"\", text)\n",
        "    # text = sub(r\"<br />\", \"\", text)\n",
        "    # text = sub(r\"br_/\", \"\", text)\n",
        "\n",
        "\n",
        "    text = sub(r\"positive\", \"sh0\", text)\n",
        "    text = sub(r\"negative\", \"positive\", text)\n",
        "    text = sub(r\"sh0\", \"negative\", text)\n",
        "    #removing numbers\n",
        "    # text = ''.join([i for i in text if not i.isdigit()])\n",
        "    #text = sub(r\" s\", \"\", text)\n",
        "    text = sub(r\"\\s{2,}\", \" \", text)\n",
        "    #text.apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in (stop)])) \n",
        "    text = text.split()\n",
        "    text1=[]\n",
        "    # Removing stopwords\n",
        "    for i in range (len(text)):\n",
        "      if(text[i].lower() not in stop):\n",
        "        text1.append(text[i])\n",
        "    return text1\n",
        "\n",
        "\n",
        "df['Summary'] = df['Summary'].apply(lambda x: text_to_word_list(x))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeiJ8M2DFSqm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "outputId": "a2074786-ea7f-4a9a-8f66-4646d5c293af"
      },
      "source": [
        "df['Summary']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     [53, journalists, mumbai, found, negative, cov...\n",
              "1     [jaipur, newborn, baby, tested, negative, coro...\n",
              "2     [sad, share, lost, gurmail, singh, kanungo, ye...\n",
              "3     [fifteen, indian, states, union, territories, ...\n",
              "4     [pending, mass, vaccination, nagarik, dharma, ...\n",
              "5     [bhubaneswar, banamali, sethi, drove, ambulanc...\n",
              "6     [earlier, week, us, officials, said, number, a...\n",
              "7     [doctor, geriatric, department, aiims, urged, ...\n",
              "8     [sellers, market, government, india, entrepris...\n",
              "9     [home, quarantine, strict, 12, 470, home, quar...\n",
              "10    [stating, today, official, spokesman, said, ha...\n",
              "11    [even, religion, continues, lay, claim, core, ...\n",
              "12    [march, 26, day, national, lockdown, announced...\n",
              "13    [chennai, vice, president, venkaiah, naidu, we...\n",
              "14    [empowered, group, also, got, 30, molecular, t...\n",
              "15    [new, delhi, centre, preparing, procure, thous...\n",
              "16    [gujarat, state, government, offices, 4, 000, ...\n",
              "17    [seven, states, doubling, rates, 20, 30, days,...\n",
              "18    [people, districts, guarding, borders, check, ...\n",
              "19    [indore, 18, people, testing, negative, novel,...\n",
              "20    [day, west, bengal, chief, minister, mamata, b...\n",
              "21    [deceased, first, undergone, treatment, two, p...\n",
              "22    [new, delhi, housekeeper, working, lok, sabha,...\n",
              "23    [according, data, oxford, tracker, india, cons...\n",
              "24    [meanwhile, covid, 19, negative, patients, ris...\n",
              "25    [35, year, old, man, whose, father, died, coro...\n",
              "26    [one, biggest, cost, components, reagents, pri...\n",
              "27    [kerala, karnataka, reported, 408, cases, deat...\n",
              "28    [senior, tax, official, said, lockdown, given,...\n",
              "29    [thane, municipal, corporation, identified, 15...\n",
              "30    [even, total, coronavirus, cases, rise, pakist...\n",
              "31    [minister, said, parameters, stable, oxygen, s...\n",
              "32    [special, bond, india, maldives, strengthens, ...\n",
              "33    [500, 600, rt, pcr, tests, done, per, day, hea...\n",
              "34    [acting, swiftly, union, home, ministry, also,...\n",
              "35    [mumbai, coronavirus, pandemic, india, may, pe...\n",
              "36    [state, minister, health, naba, kishore, das, ...\n",
              "37    [state, minister, health, naba, kishore, das, ...\n",
              "38    [mumbai, aim, prioritise, mental, health, coro...\n",
              "39    [mumbai, maharashtra, sunday, recorded, highes...\n",
              "40    [appreciating, roles, played, health, minister...\n",
              "41    [police, stepped, vigil, barricades, erected, ...\n",
              "42    [new, delhi, prime, minister, narendra, modi, ...\n",
              "Name: Summary, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0u1yxi_K2m2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "outputId": "778e875c-df6c-4536-d985-304ed067cbab"
      },
      "source": [
        "# Creating bigrams of phrases\n",
        "sent = [row for row in df['Summary']]\n",
        "phrases = Phrases(sent, min_count=1, progress_per=5000)\n",
        "bigram = Phraser(phrases)\n",
        "sentences = bigram[sent]\n",
        "sentences[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['jaipur',\n",
              " 'newborn',\n",
              " 'baby',\n",
              " 'tested_negative',\n",
              " 'coronavirus',\n",
              " 'rajasthans',\n",
              " 'nagaur',\n",
              " 'district',\n",
              " 'official_said',\n",
              " 'monday',\n",
              " 'baby',\n",
              " 'born',\n",
              " 'saturday',\n",
              " 'coronavirus_negative',\n",
              " 'dr',\n",
              " 'shadab',\n",
              " 'ali',\n",
              " 'charge',\n",
              " 'basni',\n",
              " 'primary',\n",
              " 'health',\n",
              " 'centre',\n",
              " 'pregnant',\n",
              " 'woman',\n",
              " 'admitted',\n",
              " 'informed',\n",
              " 'family',\n",
              " 'newborn',\n",
              " 'coronavirus_negative',\n",
              " 'test',\n",
              " 'report',\n",
              " 'baby',\n",
              " 'came',\n",
              " 'sunday',\n",
              " 'mother',\n",
              " 'father',\n",
              " 'family_members',\n",
              " 'covid_19',\n",
              " 'patients',\n",
              " 'nagaur',\n",
              " 'chief_medical',\n",
              " 'health_officer',\n",
              " 'dr',\n",
              " 'sukumar',\n",
              " 'kashyap',\n",
              " 'said']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OQ91IdlviSQ",
        "colab_type": "text"
      },
      "source": [
        "## Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peLe2OImJePt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "49cf83ae-6475-4e48-e834-6a2cda56774e"
      },
      "source": [
        "# Implementation of word2vec algorithm\n",
        "\n",
        "w2v_model = Word2Vec(min_count=3,\n",
        "                     window=10,\n",
        "                     size=200,\n",
        "                     sample=1e-5, \n",
        "                     alpha=0.04, \n",
        "                     min_alpha=0.0007, \n",
        "                     negative=20,\n",
        "                     workers=multiprocessing.cpu_count()-1)\n",
        "\n",
        "start = time()\n",
        "\n",
        "w2v_model.build_vocab(sentences, progress_per=50000)\n",
        "\n",
        "print('Time to build vocab: {} mins'.format(round((time() - start) / 60, 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to build vocab: 0.0 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OyTRYXFKkkU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3b787dd7-a036-4013-d752-139cfa0aa40d"
      },
      "source": [
        "# Training the word2vec model\n",
        "start = time()\n",
        "\n",
        "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
        "\n",
        "print('Time to train the model: {} mins'.format(round((time() - start) / 60, 2)))\n",
        "\n",
        "w2v_model.init_sims(replace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to train the model: 0.01 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBKuN_CvMFQa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "44c30050-828a-4f05-cf44-730017a3db93"
      },
      "source": [
        "# Saving the word2vec model\n",
        "\n",
        "w2v_model.save(\"word2vec.model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjVj4qUVRGjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Joining the splitted words and bigrams of words to create the sentence again\n",
        "df['Summary'] = df['Summary'].apply(lambda x: ' '.join(bigram[x]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uau5NvtOQlrm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "5bdfce27-9752-4144-901a-491733d858f3"
      },
      "source": [
        "df['Summary'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    53 journalists mumbai found_negative covid_19 ...\n",
              "1    jaipur newborn baby tested_negative coronaviru...\n",
              "2    sad share lost gurmail singh kanungo yesterday...\n",
              "3    fifteen indian states union territories accoun...\n",
              "4    pending mass vaccination nagarik dharma yuddha...\n",
              "Name: Summary, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeqOhuEsMM0w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "0fd1e171-d386-4ca8-9f90-10e395187520"
      },
      "source": [
        "# Loading the word vectors\n",
        "word_vectors = Word2Vec.load(\"/content/word2vec.model\").wv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fzFlTBpvoSS",
        "colab_type": "text"
      },
      "source": [
        "## K-Means clustering algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHMZfy_cNEoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# K-Means clustering model\n",
        "\n",
        "model = KMeans(n_clusters=2, max_iter=1000, n_init=10, random_state=75).fit(X=word_vectors.vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVPuO_BUNfeF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "39877f35-f78f-48da-8782-ef4fe2781f69"
      },
      "source": [
        "# Checking what word vectors are most similar in terms of cosine similarity to coordinates of first cluster\n",
        "\n",
        "word_vectors.similar_by_vector(model.cluster_centers_[0], topn=10, restrict_vocab=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('kerala', 0.6360455751419067),\n",
              " ('4', 0.6050294637680054),\n",
              " ('covid_19', 0.5938774347305298),\n",
              " ('officials_said', 0.5875084400177002),\n",
              " ('days', 0.5684670209884644),\n",
              " ('report', 0.5435541868209839),\n",
              " ('people', 0.5435150861740112),\n",
              " ('one', 0.5430293083190918),\n",
              " ('day', 0.5383172035217285),\n",
              " ('six_inter', 0.5344622135162354)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unIuh1TzNhll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assigning cluster centers\n",
        "positive_cluster_center = model.cluster_centers_[0]\n",
        "negative_cluster_center = model.cluster_centers_[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p17Gx8ONoXV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7aea9e65-edf5-455f-e192-6e0820f185f2"
      },
      "source": [
        "# Assigning clusters\n",
        "\n",
        "words = pd.DataFrame(word_vectors.vocab.keys())\n",
        "words.columns = ['words']\n",
        "words['vectors'] = words.words.apply(lambda x: word_vectors.wv[f'{x}'])\n",
        "words['cluster'] = words.vectors.apply(lambda x: model.predict([np.array(x)]))\n",
        "words.cluster = words.cluster.apply(lambda x: x[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPkNqG9sNvHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words['cluster_value'] = [1 if i==0 else -1 for i in words.cluster]\n",
        "words['closeness_score'] = words.apply(lambda x: 1/(model.transform([x.vectors]).min()), axis=1)\n",
        "words['sentiment_coeff'] = words.closeness_score * words.cluster_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nLdIkOHN0YC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "fdb7ca97-a035-456f-d86c-a4b5e9b8667f"
      },
      "source": [
        "words.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>vectors</th>\n",
              "      <th>cluster</th>\n",
              "      <th>cluster_value</th>\n",
              "      <th>closeness_score</th>\n",
              "      <th>sentiment_coeff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>journalists</td>\n",
              "      <td>[0.015491067, 0.080296226, -0.112258576, 0.051...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.034974</td>\n",
              "      <td>1.034974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mumbai</td>\n",
              "      <td>[-0.060328998, 0.032514807, 0.082572155, 0.003...</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1.034661</td>\n",
              "      <td>-1.034661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>covid_19</td>\n",
              "      <td>[0.05401922, -0.0401605, -0.009028154, -0.0023...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.197642</td>\n",
              "      <td>1.197642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>karnataka</td>\n",
              "      <td>[0.037441216, -0.12201297, 0.02246373, -0.0364...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.095556</td>\n",
              "      <td>1.095556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>chief_minister</td>\n",
              "      <td>[0.044404477, 0.044712942, -0.07513642, -0.043...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.040898</td>\n",
              "      <td>1.040898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>tuesday</td>\n",
              "      <td>[-0.094029024, -0.0637704, 0.038474645, -0.030...</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1.037901</td>\n",
              "      <td>-1.037901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>department</td>\n",
              "      <td>[-0.058376696, 0.027690126, -0.043274246, 0.05...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.069596</td>\n",
              "      <td>1.069596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>state</td>\n",
              "      <td>[0.04801613, -0.037459616, -0.083501406, -0.07...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.099289</td>\n",
              "      <td>1.099289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>infection</td>\n",
              "      <td>[0.02234778, 0.021489538, -0.07686617, -0.0019...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.128612</td>\n",
              "      <td>1.128612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>news</td>\n",
              "      <td>[0.09101163, 0.0112021575, 0.07615463, 0.10063...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.050882</td>\n",
              "      <td>1.050882</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            words  ... sentiment_coeff\n",
              "0     journalists  ...        1.034974\n",
              "1          mumbai  ...       -1.034661\n",
              "2        covid_19  ...        1.197642\n",
              "3       karnataka  ...        1.095556\n",
              "4  chief_minister  ...        1.040898\n",
              "5         tuesday  ...       -1.037901\n",
              "6      department  ...        1.069596\n",
              "7           state  ...        1.099289\n",
              "8       infection  ...        1.128612\n",
              "9            news  ...        1.050882\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIxSnfMfN5A4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Exporting to csv format\n",
        "words[['words', 'sentiment_coeff']].to_csv('sentiment_dictionary.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Cm2lS8EN-3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the csv file into final file\n",
        "final_file = df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR-6mAD_PRec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_map = pd.read_csv('/content/sentiment_dictionary.csv')\n",
        "sentiment_dict = dict(zip(sentiment_map.words.values, sentiment_map.sentiment_coeff.values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KU3A9wCnvt6v",
        "colab_type": "text"
      },
      "source": [
        "## Tfidf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rahEO_YaTMuO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f3bce85e-4741-44ab-814b-b9715a1cf5cf"
      },
      "source": [
        "# Getting tfidf scores of words in every sentence, and replacing them with their associated tfidf weights:\n",
        "\n",
        "file_weighting = final_file.copy()\n",
        "\n",
        "tfidf = TfidfVectorizer(tokenizer=lambda y: y.split(), norm=None)\n",
        "tfidf.fit(file_weighting.Summary)\n",
        "features = pd.Series(tfidf.get_feature_names())\n",
        "transformed = tfidf.transform(file_weighting.Summary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmpzoG6DTyIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Replacing words in sentences with their tfidf scores\n",
        "\n",
        "def create_tfidf_dictionary(x, transformed_file, features):\n",
        "    '''\n",
        "    create dictionary for each input sentence x, where each word has assigned its tfidf score\n",
        "    \n",
        "    x - row of dataframe, containing sentences, and their indexes,\n",
        "    transformed_file - all sentences transformed with TfidfVectorizer\n",
        "    features - names of all words in corpus used in TfidfVectorizer\n",
        "\n",
        "    '''\n",
        "    vector_coo = transformed_file[x.name].tocoo()\n",
        "    vector_coo.col = features.iloc[vector_coo.col].values\n",
        "    dict_from_coo = dict(zip(vector_coo.col, vector_coo.data))\n",
        "    return dict_from_coo\n",
        "\n",
        "def replace_tfidf_words(x, transformed_file, features):\n",
        "    '''\n",
        "    replacing each word with it's calculated tfidf dictionary with scores of each word\n",
        "    x - row of dataframe, containing sentences, and their indexes,\n",
        "    transformed_file - all sentences transformed with TfidfVectorizer\n",
        "    features - names of all words in corpus used in TfidfVectorizer\n",
        "    '''\n",
        "    dictionary = create_tfidf_dictionary(x, transformed_file, features)   \n",
        "    return list(map(lambda y:dictionary[f'{y}'], x.Summary.split()))\n",
        "\n",
        "replaced_tfidf_scores = file_weighting.apply(lambda x: replace_tfidf_words(x, transformed, features), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBT42N8HUv-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Replacing words in sentences with their sentiment score\n",
        "\n",
        "def replace_sentiment_words(word, sentiment_dict):\n",
        "    '''\n",
        "    replacing each word with its associated sentiment score from sentiment dict\n",
        "    '''\n",
        "    try:\n",
        "        out = sentiment_dict[word]\n",
        "    except KeyError:\n",
        "        out = 0\n",
        "    return out\n",
        "\n",
        "replaced_closeness_scores = file_weighting.Summary.apply(lambda x: list(map(lambda y: replace_sentiment_words(y, sentiment_dict), x.split())))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7C3DBdTVM_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Merging both previous steps and getting the predictions\n",
        "\n",
        "replacement_df = pd.DataFrame(data=[replaced_closeness_scores, replaced_tfidf_scores, file_weighting.Summary]).T\n",
        "replacement_df.columns = ['sentiment_coeff', 'tfidf_scores', 'sentence']\n",
        "replacement_df['sentiment_rate'] = replacement_df.apply(lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']), axis=1)\n",
        "replacement_df['prediction'] = (replacement_df.sentiment_rate>0).astype('int8')\n",
        "#replacement_df['sentiment'] = \"\"\n",
        "#replacement_df['sentiment'] = [1 if i==1 else 0 for i in replacement_df.sentiment]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0tcDTqEWh9w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "468d2dd3-27b1-4dde-d743-ccd8a8de99c3"
      },
      "source": [
        "replacement_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment_coeff</th>\n",
              "      <th>tfidf_scores</th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment_rate</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0, 1.0349744428126229, -1.0346610751646983, 0...</td>\n",
              "      <td>[4.091042453358316, 14.742309381000606, 2.9924...</td>\n",
              "      <td>53 journalists mumbai found_negative covid_19 ...</td>\n",
              "      <td>69.746986</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[0, 0, -1.0020999165456832, 1.0380016512141024...</td>\n",
              "      <td>[4.091042453358316, 8.182084906716632, 12.2731...</td>\n",
              "      <td>jaipur newborn baby tested_negative coronaviru...</td>\n",
              "      <td>-73.638409</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, -1.0134110630550304, ...</td>\n",
              "      <td>[8.182084906716632, 4.091042453358316, 3.68557...</td>\n",
              "      <td>sad share lost gurmail singh kanungo yesterday...</td>\n",
              "      <td>-56.491954</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0, -1.0288367335333302, -1.0591179790989944, ...</td>\n",
              "      <td>[4.091042453358316, 3.3978952727983707, 2.7047...</td>\n",
              "      <td>fifteen indian states union territories accoun...</td>\n",
              "      <td>-6.655883</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0, -1.0133127612691422, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[4.091042453358316, 7.371154690500303, 4.09104...</td>\n",
              "      <td>pending mass vaccination nagarik dharma yuddha...</td>\n",
              "      <td>-84.061345</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     sentiment_coeff  ... prediction\n",
              "0  [0, 1.0349744428126229, -1.0346610751646983, 0...  ...          1\n",
              "1  [0, 0, -1.0020999165456832, 1.0380016512141024...  ...          0\n",
              "2  [0, 0, 0, 0, 0, 0, 0, 0, -1.0134110630550304, ...  ...          0\n",
              "3  [0, -1.0288367335333302, -1.0591179790989944, ...  ...          0\n",
              "4  [0, -1.0133127612691422, 0, 0, 0, 0, 0, 0, 0, ...  ...          0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSFiZUtfW0Kc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZFtMGw0YEGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assigning the feature to required dataframe\n",
        "df[\"sentiment_prediction\"] = replacement_df['prediction']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB0jTfkziDzK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "122f5f7a-bd4f-478e-aff6-2e3d46025895"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date-Time</th>\n",
              "      <th>Title</th>\n",
              "      <th>Content</th>\n",
              "      <th>Article URL</th>\n",
              "      <th>All_Content</th>\n",
              "      <th>Summary</th>\n",
              "      <th>sentiment_prediction</th>\n",
              "      <th>Actual_Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21 Apr, 2020, 01:52PM IST</td>\n",
              "      <td>Covid-19: Karnataka to collect samples of jour...</td>\n",
              "      <td>The directions followed a request from Educati...</td>\n",
              "      <td>https://economictimes.indiatimes.com//news/pol...</td>\n",
              "      <td>After 53 journalists in Mumbai were found posi...</td>\n",
              "      <td>53 journalists mumbai found_negative covid_19 ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20 Apr, 2020, 07:33AM IST</td>\n",
              "      <td>Newborn tests positive for COVID-19 in Rajasth...</td>\n",
              "      <td>Dr Shadab Ali, in-charge of Basni primary heal...</td>\n",
              "      <td>https://economictimes.indiatimes.com//news/pol...</td>\n",
              "      <td>Jaipur: A newborn baby has tested positive for...</td>\n",
              "      <td>jaipur newborn baby tested_negative coronaviru...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18 Apr, 2020, 12:17PM IST</td>\n",
              "      <td>Police officer dies of COVID-19 in Ludhiana</td>\n",
              "      <td>The 52-year-old Ludhiana assistant commissione...</td>\n",
              "      <td>https://economictimes.indiatimes.com//news/pol...</td>\n",
              "      <td>The 52-year-old Ludhiana assistant commissione...</td>\n",
              "      <td>sad share lost gurmail singh kanungo yesterday...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10 Apr, 2020, 02:14AM IST</td>\n",
              "      <td>The Covid curve: How the states fare</td>\n",
              "      <td>Data suggests that some of the 15 states/UTs n...</td>\n",
              "      <td>https://economictimes.indiatimes.com//news/pol...</td>\n",
              "      <td>Fifteen Indian states and Union Territories ac...</td>\n",
              "      <td>fifteen indian states union territories accoun...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15 Apr, 2020, 06:33PM IST</td>\n",
              "      <td>Covid fight needs women to be agents of change</td>\n",
              "      <td>Women civil servants and police at Centre, sta...</td>\n",
              "      <td>https://economictimes.indiatimes.com//news/pol...</td>\n",
              "      <td>By LAKSHMI PURI In our Covid wars, itâ€™s time t...</td>\n",
              "      <td>pending mass vaccination nagarik dharma yuddha...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Date-Time  ... Actual_Sentiment\n",
              "0  21 Apr, 2020, 01:52PM IST  ...                0\n",
              "1  20 Apr, 2020, 07:33AM IST  ...                0\n",
              "2  18 Apr, 2020, 12:17PM IST  ...                0\n",
              "3  10 Apr, 2020, 02:14AM IST  ...                0\n",
              "4  15 Apr, 2020, 06:33PM IST  ...                1\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCMfgivwl1gC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9962c345-e786-4022-d13b-c895a31de036"
      },
      "source": [
        "# Function for measuring accuracy\n",
        "c=0\n",
        "for index, row in df.iterrows():\n",
        "  if(row['sentiment_prediction']==row['Actual_Sentiment']):\n",
        "    c+=1\n",
        "acc = c/len(df)\n",
        "print(\"Accuracy Percentage: \", acc )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Percentage:  0.5116279069767442\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T90TLrTLtFJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Exporting the dataset\n",
        "df1.to_excel('covid_sentiment.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGisA8T9tCWd",
        "colab_type": "text"
      },
      "source": [
        "# Implementation of Sentiment Analysis using TextBlob, Afinn, Vader and SentiWordNet libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyBshl8MtFNG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "6f83ef87-7c02-451e-e981-16eee076d3a8"
      },
      "source": [
        "# Downloading dependecies \n",
        "!pip install textblob\n",
        "!pip install textsearch\n",
        "!pip install contractions\n",
        "!pip install afinn\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.6/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.12.0)\n",
            "Collecting textsearch\n",
            "  Downloading https://files.pythonhosted.org/packages/42/a8/03407021f9555043de5492a2bd7a35c56cc03c2510092b5ec018cae1bbf1/textsearch-0.0.17-py2.py3-none-any.whl\n",
            "Collecting pyahocorasick\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz (312kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 317kB 6.4MB/s \n",
            "\u001b[?25hCollecting Unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 245kB 13.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.0-cp36-cp36m-linux_x86_64.whl size=81705 sha256=292e44cfb4cf60d82ae7adacadac54338942ef2c26b92bba4f38f75d9ae77354\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/90/61/87a55f5b459792fbb2b7ba6b31721b06ff5cf6bde541b40994\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: pyahocorasick, Unidecode, textsearch\n",
            "Successfully installed Unidecode-1.1.1 pyahocorasick-1.4.0 textsearch-0.0.17\n",
            "Collecting contractions\n",
            "  Downloading https://files.pythonhosted.org/packages/85/41/c3dfd5feb91a8d587ed1a59f553f07c05f95ad4e5d00ab78702fbf8fe48a/contractions-0.0.24-py2.py3-none-any.whl\n",
            "Requirement already satisfied: textsearch in /usr/local/lib/python3.6/dist-packages (from contractions) (0.0.17)\n",
            "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.1.1)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.4.0)\n",
            "Installing collected packages: contractions\n",
            "Successfully installed contractions-0.0.24\n",
            "Collecting afinn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/e5/ffbb7ee3cca21ac6d310ac01944fb163c20030b45bda25421d725d8a859a/afinn-0.1.tar.gz (52kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 3.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: afinn\n",
            "  Building wheel for afinn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for afinn: filename=afinn-0.1-cp36-none-any.whl size=53452 sha256=895313e44c325d6979a5c1d88770c827ec520bcb13b8fc33c4a57fe7c4910be5\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/1c/de/428301f3333ca509dcf20ff358690eb23a1388fbcbbde008b2\n",
            "Successfully built afinn\n",
            "Installing collected packages: afinn\n",
            "Successfully installed afinn-0.1\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyGlOVCktSlo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading dependencies\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import textblob\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "np.set_printoptions(precision=2, linewidth=80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNQ53a17qIrc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dropping duplicate rows if any \n",
        "df2 = df1.dropna().drop_duplicates().reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKujsk49WgbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test\n",
        "df2=df\n",
        "df1=df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J72NhjuZqL2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Pre-processing\n",
        "\n",
        "def text_to_word_list(text):\n",
        "    text = str(text)\n",
        "    text = text.lower()\n",
        "\n",
        "    # Clean the text\n",
        "    text = sub(r\"[^A-Za-z0-9^,!?.\\/'+]\", \" \", text)\n",
        "    text = sub(r\",\", \" \", text)\n",
        "    text = sub(r\"\\.\", \" \", text)\n",
        "    text = sub(r\"!\", \" ! \", text)\n",
        "    text = sub(r\"\\?\", \" ? \", text)\n",
        "    text = sub(r\"'\", \"\", text)\n",
        "    text = sub(r'\"', \" \", text)\n",
        "    text = sub(r\":\", \" : \", text)\n",
        "    text = sub(r\"\\s{2,}\", \" \", text)\n",
        "    # text = sub(r\"positive\", \"sh0\", text)\n",
        "    # text = sub(r\"negative\", \"positive\", text)\n",
        "    # text = sub(r\"sh0\", \"negative\", text)\n",
        "    text = ''.join([i for i in text if not i.isdigit()])\n",
        "    #text = text.split()\n",
        "    return text\n",
        "\n",
        "\n",
        "df2['Summary'] = df2['Summary'].apply(lambda x: text_to_word_list(x))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyD3RLPuqROD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "f5499aab-3b9a-435d-99ab-275f06e098b0"
      },
      "source": [
        "df2['Summary'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     journalists mumbai found negative covid  karn...\n",
              "1    jaipur newborn baby tested negative coronaviru...\n",
              "2    sad share lost gurmail singh kanungo yesterday...\n",
              "3    fifteen indian states union territories accoun...\n",
              "4    pending mass vaccination nagarik dharma yuddha...\n",
              "Name: Summary, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXSmfWHovbba",
        "colab_type": "text"
      },
      "source": [
        "## TextBlob"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4Ae6ImwpNC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating an attribute for storing textblob prediction values\n",
        "df1['textblob_prediction'] = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38LwIaahqpge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implementing textblob\n",
        "\n",
        "for index, row in df2.iterrows():\n",
        "    #print('Title:', row['Title'])\n",
        "    s = row['Summary']\n",
        "    sentiment = textblob.TextBlob(s).sentiment.polarity\n",
        "    if(sentiment < 0):\n",
        "      i = 0\n",
        "    elif(sentiment >= 0):\n",
        "      i=1\n",
        "    df1.at[index,'textblob_prediction'] = int(i)\n",
        "    #print('Predicted Sentiment polarity:', sentiment)\n",
        "    #print('-'*60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiXVFBgVoS2b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "cfeb76b1-c88d-47e2-f58e-0c66d90dd3df"
      },
      "source": [
        "# Function for measuring accuracy\n",
        "c=0\n",
        "for index, row in df1.iterrows():\n",
        "  if(row['textblob_prediction']==row['Actual_Sentiment']):\n",
        "    c+=1\n",
        "acc = c/len(df1)\n",
        "print(\"Accuracy Percentage: \", acc )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Percentage:  0.5581395348837209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6FaVLNVsCya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1XqloZSvXqj",
        "colab_type": "text"
      },
      "source": [
        "## Afinn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XZzaC5Xpwe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating an attribute for storing Afinn prediction values\n",
        "df1['afinn_prediction'] = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao0fOqWbwvtj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implementing Afinn\n",
        "from afinn import Afinn\n",
        "\n",
        "afn = Afinn(emoticons=True)\n",
        "\n",
        "for index, row in df2.iterrows():\n",
        "    s = row['Summary']\n",
        "    sentiment = afn.score(s)\n",
        "    if(sentiment < 0):\n",
        "      i = 0\n",
        "    elif(sentiment >= 0):\n",
        "      i=1\n",
        "    df1.at[index,'afinn_prediction'] = int(i)    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4RLcIdlwwkt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "df391e36-9ae8-435b-8e23-87bda1db9038"
      },
      "source": [
        "# Function for measuring accuracy\n",
        "c=0\n",
        "for index, row in df1.iterrows():\n",
        "  if(row['afinn_prediction']==row['Actual_Sentiment']):\n",
        "    c+=1\n",
        "acc = c/len(df1)\n",
        "print(\"Accuracy Percentage: \", acc )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Percentage:  0.6046511627906976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10C9V66JqKTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4UntvD9vVAZ",
        "colab_type": "text"
      },
      "source": [
        "## Vader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqyx4NCsqszq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating an attribute for storing Vader prediction values\n",
        "df1['vader_prediction'] = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9XkgmeKxfMA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "fe6f32ae-a6e8-46bf-e258-73dbbcae1233"
      },
      "source": [
        "# Using Vader (Valence Aware Dictionary and sEntiment Reasoner)\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "def analyze_sentiment_vader_lexicon(review, \n",
        "                                    threshold=0.1,\n",
        "                                    verbose=False):    \n",
        "    # analyze the sentiment for review\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    scores = analyzer.polarity_scores(review)\n",
        "    # get aggregate scores and final sentiment\n",
        "    agg_score = scores['compound']\n",
        "    final_sentiment = 'positive' if agg_score >= threshold\\\n",
        "                                   else 'negative'\n",
        "    if verbose:\n",
        "        # display detailed sentiment statistics\n",
        "        positive = str(round(scores['pos'], 2)*100)+'%'\n",
        "        final = round(agg_score, 2)\n",
        "        negative = str(round(scores['neg'], 2)*100)+'%'\n",
        "        neutral = str(round(scores['neu'], 2)*100)+'%'\n",
        "        sentiment_frame = pd.DataFrame([[final_sentiment, final, positive,\n",
        "                                        negative, neutral]],\n",
        "                                        columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'], \n",
        "                                                                      ['Predicted Sentiment', 'Polarity Score',\n",
        "                                                                       'Positive', 'Negative', 'Neutral']], \n",
        "                                                              codes=[[0,0,0,0,0],[0,1,2,3,4]]))\n",
        "        # print(sentiment_frame)\n",
        "    \n",
        "    return final_sentiment\n",
        "\n",
        "for index, row in df2.iterrows():\n",
        "    s = row['Summary']\n",
        "    sentiment = analyze_sentiment_vader_lexicon(s, threshold=0.4, verbose=True)\n",
        "    if(sentiment == 'negative'):\n",
        "      i = 0\n",
        "    elif(sentiment == 'positive'):\n",
        "      i = 1\n",
        "    df1.at[index,'vader_prediction'] = int(i)  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc2eOG_Gydp_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0d40f92d-13e6-437e-d2ba-34e0ccea0722"
      },
      "source": [
        "# Function for measuring accuracy\n",
        "c=0\n",
        "for index, row in df1.iterrows():\n",
        "  if(row['vader_prediction']==row['Actual_Sentiment']):\n",
        "    c+=1\n",
        "acc = c/len(df1)\n",
        "print(\"Accuracy Percentage: \", acc )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Percentage:  0.6976744186046512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jM-1TLD4oQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJKmMU3fvQpl",
        "colab_type": "text"
      },
      "source": [
        "## SentiWordNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zyUhncz7Jh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating an attribute for storing SentiWordNet prediction values\n",
        "df1['senti_prediction'] = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYuW4YUX50vC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "26f11496-30a7-4cd2-8e58-9794074310d1"
      },
      "source": [
        "# Downloading dependencies and loading libraries\n",
        "nltk.download('wordnet')\n",
        "nltk.download('sentiwordnet')\n",
        "!pip install text_normalizer\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import text_normalizer as tn\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en', parse = False, tag=False, entity=False)\n",
        "\n",
        "# Testing the SentiWordNet library on a test sentence\n",
        "awesome = list(swn.senti_synsets('awesome', 'a'))[0]\n",
        "print('Positive Polarity Score:', awesome.pos_score())\n",
        "print('Negative Polarity Score:', awesome.neg_score())\n",
        "print('Objective Score:', awesome.obj_score())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/sentiwordnet.zip.\n",
            "Collecting text_normalizer\n",
            "  Downloading https://files.pythonhosted.org/packages/b7/98/b49628d90d5793e7369e25d6a84f9ca4a1fc6472d848d15daa9bf9129ad7/text-normalizer-0.1.3.tar.gz\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from text_normalizer) (1.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->text_normalizer) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->text_normalizer) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas->text_normalizer) (1.18.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->text_normalizer) (1.12.0)\n",
            "Building wheels for collected packages: text-normalizer\n",
            "  Building wheel for text-normalizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for text-normalizer: filename=text_normalizer-0.1.3-cp36-cp36m-linux_x86_64.whl size=166142 sha256=c2764d85f0d398bb682cb723724fb92ddb89e092c579ebcd8b5a6603f0eb7696\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/15/93/c3a18073b2bb6c6476fc1c65a9870bb0e10d939c324b40a5cc\n",
            "Successfully built text-normalizer\n",
            "Installing collected packages: text-normalizer\n",
            "Successfully installed text-normalizer-0.1.3\n",
            "Positive Polarity Score: 0.875\n",
            "Negative Polarity Score: 0.125\n",
            "Objective Score: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4U-sC_u51e0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implementation of SentiWordNet\n",
        "def analyze_sentiment_sentiwordnet_lexicon(review,\n",
        "                                           verbose=False):\n",
        "\n",
        "    # tokenize and POS tag text tokens\n",
        "    tagged_text = [(token.text, token.tag_) for token in nlp(review)]\n",
        "    pos_score = neg_score = token_count = obj_score = 0\n",
        "    # get wordnet synsets based on POS tags\n",
        "    # get sentiment scores if synsets are found\n",
        "    for word, tag in tagged_text:\n",
        "        ss_set = None\n",
        "        if 'NN' in tag and list(swn.senti_synsets(word, 'n')):\n",
        "            ss_set = list(swn.senti_synsets(word, 'n'))[0]\n",
        "        elif 'VB' in tag and list(swn.senti_synsets(word, 'v')):\n",
        "            ss_set = list(swn.senti_synsets(word, 'v'))[0]\n",
        "        elif 'JJ' in tag and list(swn.senti_synsets(word, 'a')):\n",
        "            ss_set = list(swn.senti_synsets(word, 'a'))[0]\n",
        "        elif 'RB' in tag and list(swn.senti_synsets(word, 'r')):\n",
        "            ss_set = list(swn.senti_synsets(word, 'r'))[0]\n",
        "        # if senti-synset is found        \n",
        "        if ss_set:\n",
        "            # add scores for all found synsets\n",
        "            pos_score += ss_set.pos_score()\n",
        "            neg_score += ss_set.neg_score()\n",
        "            obj_score += ss_set.obj_score()\n",
        "            token_count += 1\n",
        "    \n",
        "    # aggregate final scores\n",
        "    final_score = pos_score - neg_score\n",
        "    norm_final_score = round(float(final_score) / token_count, 2)\n",
        "    final_sentiment = 'positive' if norm_final_score >= 0 else 'negative'\n",
        "    if verbose:\n",
        "        norm_obj_score = round(float(obj_score) / token_count, 2)\n",
        "        norm_pos_score = round(float(pos_score) / token_count, 2)\n",
        "        norm_neg_score = round(float(neg_score) / token_count, 2)\n",
        "        # to display results in a nice table\n",
        "        # sentiment_frame = pd.DataFrame([[final_sentiment, norm_obj_score, norm_pos_score, \n",
        "        #                                  norm_neg_score, norm_final_score]],\n",
        "        #                                columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'], \n",
        "        #                                                      ['Predicted Sentiment', 'Objectivity',\n",
        "        #                                                       'Positive', 'Negative', 'Overall']], \n",
        "        #                                                      labels=[[0,0,0,0,0],[0,1,2,3,4]]))\n",
        "        # print(sentiment_frame)\n",
        "        \n",
        "    return final_sentiment\n",
        "\n",
        "for index, row in df1.iterrows():\n",
        "\n",
        "    a = row['Summary']\n",
        "    sentiment = analyze_sentiment_sentiwordnet_lexicon(a, verbose=True)    \n",
        "    if(sentiment == 'negative'):\n",
        "      i = 0\n",
        "    elif(sentiment == 'positive'):\n",
        "      i = 1\n",
        "    df1.at[index,'senti_prediction'] = int(i) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v1UUd1V6Qny",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "4ca6a69a-7660-45ad-ef14-a9aee578dde2"
      },
      "source": [
        "# Function for measuring accuracy\n",
        "c=0\n",
        "for index, row in df1.iterrows():\n",
        "  if(row['senti_prediction']==row['Actual_Sentiment']):\n",
        "    c+=1\n",
        "acc = c/len(df1)\n",
        "print(\"Accuracy Percentage: \", acc )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Percentage:  0.6976744186046512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPjx8_Xz7U2m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "outputId": "adf3066a-5935-48f9-bf1b-76e5f6ed336f"
      },
      "source": [
        "# Visualizing the final dataframe\n",
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date-Time</th>\n",
              "      <th>Title</th>\n",
              "      <th>Content</th>\n",
              "      <th>Article URL</th>\n",
              "      <th>All_Content</th>\n",
              "      <th>Summary</th>\n",
              "      <th>sentiment_prediction</th>\n",
              "      <th>Actual_Sentiment</th>\n",
              "      <th>textblob_prediction</th>\n",
              "      <th>afinn_prediction</th>\n",
              "      <th>vader_prediction</th>\n",
              "      <th>senti_prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21 Apr, 2020, 01:52PM IST</td>\n",
              "      <td>Covid-19: Karnataka to collect samples of jour...</td>\n",
              "      <td>The directions followed a request from Educati...</td>\n",
              "      <td>https://economictimes.indiatimes.com//news/pol...</td>\n",
              "      <td>After 53 journalists in Mumbai were found posi...</td>\n",
              "      <td>journalists mumbai found negative covid  karn...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20 Apr, 2020, 07:33AM IST</td>\n",
              "      <td>Newborn tests positive for COVID-19 in Rajasth...</td>\n",
              "      <td>Dr Shadab Ali, in-charge of Basni primary heal...</td>\n",
              "      <td>https://economictimes.indiatimes.com//news/pol...</td>\n",
              "      <td>Jaipur: A newborn baby has tested positive for...</td>\n",
              "      <td>jaipur newborn baby tested negative coronaviru...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18 Apr, 2020, 12:17PM IST</td>\n",
              "      <td>Police officer dies of COVID-19 in Ludhiana</td>\n",
              "      <td>The 52-year-old Ludhiana assistant commissione...</td>\n",
              "      <td>https://economictimes.indiatimes.com//news/pol...</td>\n",
              "      <td>The 52-year-old Ludhiana assistant commissione...</td>\n",
              "      <td>sad share lost gurmail singh kanungo yesterday...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10 Apr, 2020, 02:14AM IST</td>\n",
              "      <td>The Covid curve: How the states fare</td>\n",
              "      <td>Data suggests that some of the 15 states/UTs n...</td>\n",
              "      <td>https://economictimes.indiatimes.com//news/pol...</td>\n",
              "      <td>Fifteen Indian states and Union Territories ac...</td>\n",
              "      <td>fifteen indian states union territories accoun...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15 Apr, 2020, 06:33PM IST</td>\n",
              "      <td>Covid fight needs women to be agents of change</td>\n",
              "      <td>Women civil servants and police at Centre, sta...</td>\n",
              "      <td>https://economictimes.indiatimes.com//news/pol...</td>\n",
              "      <td>By LAKSHMI PURI In our Covid wars, itâ€™s time t...</td>\n",
              "      <td>pending mass vaccination nagarik dharma yuddha...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Date-Time  ... senti_prediction\n",
              "0  21 Apr, 2020, 01:52PM IST  ...                0\n",
              "1  20 Apr, 2020, 07:33AM IST  ...                1\n",
              "2  18 Apr, 2020, 12:17PM IST  ...                0\n",
              "3  10 Apr, 2020, 02:14AM IST  ...                1\n",
              "4  15 Apr, 2020, 06:33PM IST  ...                1\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y7UD2-q7V7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}